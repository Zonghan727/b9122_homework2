{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "04454d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d5d805",
   "metadata": {},
   "source": [
    "# Q1 Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5068e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_html_to_txt(html_content, filename):\n",
    "    desktop_path = os.path.join(os.path.expanduser('~'), 'Desktop')\n",
    "    # Create a new folder named \"Zonghan Li\" on the desktop (if it doesn't already exist)\n",
    "    folder_path = os.path.join(desktop_path, 'Zonghan Li')\n",
    "    os.makedirs(folder_path, exist_ok=True)  # The exist_ok=True ensures no error if the folder already exists\n",
    "    \n",
    "    # Determine the full path for the .txt file within the \"Zonghan Li\" folder\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    # Write the HTML source code to the file\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(str(html_content))\n",
    "    \n",
    "    print(f\"HTML source code saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "18dbe41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/1_1.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/1_2.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/1_3.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/1_4.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/1_5.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/1_6.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/1_7.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/1_8.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/1_9.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/1_10.txt\n"
     ]
    }
   ],
   "source": [
    "#get the url of press_release in\n",
    "seed_url = \"https://press.un.org/en\"\n",
    "try: \n",
    "    response = requests.get(seed_url)\n",
    "    content = response.content\n",
    "except Exception as ex:\n",
    "        print(\"Unable to access= \"+seed_url)\n",
    "        print(ex)\n",
    "soup = BeautifulSoup(content, 'lxml')\n",
    "data = soup.find_all('div', {'class': 'more-link'})\n",
    "press_release_url = [i for i in data if \"press-release\" in str(i)][0].find('a')['href']\n",
    "\n",
    "contain_crisis = 0\n",
    "page_number = 1\n",
    "while contain_crisis < 10 :\n",
    "    current_page_url = press_release_url + '?page=' + str(page_number)\n",
    "    #get the url of all the articles of press_relesae in current page\n",
    "    try: \n",
    "        response1 = requests.get(current_page_url)\n",
    "        content_press = response1.content\n",
    "    except Exception as ex:\n",
    "            print(\"Unable to access= \"+current_page_url)\n",
    "            print(ex)\n",
    "    soup_press = BeautifulSoup(content_press, 'lxml')\n",
    "    data = soup.find_all('div', {'class': 'views-row'})\n",
    "    pre = 'https://press.un.org/'\n",
    "    url_collection = []\n",
    "    for i in data:\n",
    "        url = i.find('a', href=True)['href']\n",
    "        url_collection.append(pre+url)\n",
    "    for i in url_collection: \n",
    "        try: \n",
    "            response_temp = requests.get(i)\n",
    "            content_crisis = response_temp.content\n",
    "        except Exception as ex:\n",
    "            print(\"Unable to access= \"+press_release_url)\n",
    "            print(ex)\n",
    "        if 'crisis' in str(content_crisis):\n",
    "            save_html_to_txt(content_crisis, '1_'+ str(contain_crisis+1) + '.txt')\n",
    "            contain_crisis += 1\n",
    "            if contain_crisis >=10 :\n",
    "                break\n",
    "    page_number += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96ab9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3c19ad4",
   "metadata": {},
   "source": [
    "# Q1 Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7bc1d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/2_1.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/2_2.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/2_3.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/2_4.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/2_5.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/2_6.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/2_7.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/2_8.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/2_9.txt\n",
      "HTML source code saved to: /Users/zonghanli/Desktop/Zonghan Li/2_10.txt\n"
     ]
    }
   ],
   "source": [
    "seed_url = \"https://www.europarl.europa.eu/news/en/press-room\"\n",
    "extract_number = 0\n",
    "article_number = 0\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(seed_url)\n",
    "time.sleep(5)\n",
    "load_more_button = driver.find_element(By.ID, \"continuesLoading_button\")\n",
    "driver.execute_script(\"arguments[0].click();\", load_more_button)\n",
    "time.sleep(5)\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "data = soup.find_all('article', {'class': 'ep_gridcolumn ep-m_product ep-layout_linkmode'})\n",
    "\n",
    "for article in data: \n",
    "            article_url = article.find('a', href=True)['href']\n",
    "            try: \n",
    "                response_article = requests.get(article_url)\n",
    "                content_article = response_article.content\n",
    "            except Exception as ex:\n",
    "                print(\"Unable to access= \"+article_url)\n",
    "                print(ex)\n",
    "            if 'Plenary session' in str(content_article) and 'crisis' in str(content_article):\n",
    "                save_html_to_txt(content_article, '2_'+ str(extract_number+1) + '.txt')\n",
    "                extract_number += 1\n",
    "                if extract_number >= 10:\n",
    "                    break\n",
    "if extract_number < 10:\n",
    "    while extract_number < 10:\n",
    "        \n",
    "        driver.execute_script(\"arguments[0].click();\", load_more_button)\n",
    "        time.sleep(5)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'lxml')\n",
    "        data = soup.find_all('article', {'class': 'ep_gridcolumn ep-m_product ep-layout_linkmode'})\n",
    "        \n",
    "        \n",
    "        for article in data[len(data)-15: len(data)]:\n",
    "            article_url = article.find('a', href=True)['href']\n",
    "            try: \n",
    "                response_article = requests.get(article_url)\n",
    "                content_article = response_article.content\n",
    "            except Exception as ex:\n",
    "                print(\"Unable to access= \"+article_url)\n",
    "                print(ex)\n",
    "            if 'Plenary session' in str(content_article) and 'crisis' in str(content_article):\n",
    "                save_html_to_txt(content_crisis, '2_'+ str(extract_number+1) + '.txt')\n",
    "                extract_number += 1\n",
    "                if extract_number >= 10:\n",
    "                    break\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8063197d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
